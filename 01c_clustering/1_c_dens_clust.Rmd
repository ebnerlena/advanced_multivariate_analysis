---
title: "Density estimation. Clustering."
author: "Pedro Delicado"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, 
                      comment = FALSE, error = FALSE, eval=TRUE)
#Put eval=FALSE for having just the question statements
#Put eval=TRUE for obtaining the output
```

## Reading the data: Boston Housing
We'll use the `MASS::Boston` dataset, that contains median house values from Boston neighbourhoods.
In particular we are interested in the joint distributions of centered and scaled variables `lstat` and `rm`:

```{r,fig.height=4.5,fig.width=4.5,fig.align='center',echo=TRUE,eval=TRUE}
data("Boston", package = "MASS")
X <- scale(Boston[,c(13,6)]) # scale data with standarddeviation
# because its better to work with data that is scaled,
# then you can use standardplot in both axes and data is always same distributed
plot(X,asp=1)
```

## Questions

1. We want to estimate the joint bivariate density using a kernel estimator with the same bandwith in both dimensions: $h=(a,a)$. 
For instance, the following code performs this estimation for $a=0.5$:

```{r,fig.height=4.5,fig.width=4.5,fig.align='center',echo=TRUE,eval=TRUE}
library(sm)
plot(X,asp=1,col=8)
sm.density(X,h=.5*c(1,1),display="slice",props=c(25,50,75,95),col=2,add=TRUE)
# h=.5*c(1,1) = scaling both axes
# kernel densitiy estimator result with optimal bandwidth of 0.3
```

Use the *maximum log-likelihood cross-validation method* for choosing the value of $a$, whem $a$ takes values in the vector `seq(0.1,1,by=0.1)`. Then repeat the previous density estimation using the chosen value of $a$.

*Indication:* 
Maximize in $a$ the **logarithm** of the likelihood cross-validation (instead of maximizing just the likelihood cross-validation). 
The following code evaluates the logarithm of the density estimator at point $(0,0)$:
```{r,echo=TRUE,eval=FALSE}
new.point <- matrix(c(0,0),ncol=2)
f.hat <- sm.density(X,h=.5*c(1,1),display="none",eval.grid=FALSE,
                    eval.points=new.point)
log(f.hat$estimate)
```


```{r}
va <- seq(0.1,1,by=0.1)
na <- length(va)
logLCVa <- numeric(na)

n <- dim(X)[1]

for (j in 1:na){
  a <- va[j]
  for (i in 1:n){
    new.point <- matrix(X[i,],ncol=2)
    f.hat.i <- sm.density(X[-i,],h=a*c(1,1),display="none",eval.grid=FALSE,
                    eval.points=new.point)$estimate
    logLCVa[j] <- logLCVa[j] + log(f.hat.i)
  }
}

plot(va,logLCVa,type="b")
```

```{r,fig.asp=1}
a.opt <- va[which.max(logLCVa)]

plot(X,asp=1,col=8,main=paste("Optimal a: ",a.opt))
sm.density(X,h=a.opt*c(1,1),display="slice",props=c(25,50,75,95),col=2,add=TRUE)
```


2. Do a model based clustering of these data assuming a Gaussian Mixture Model with $k=3$ classes. 
Plot the scatterplot of the data, using a different color for points in different clusters.
Use library `mclust`.

```{r clustering}
k<-3
library(mclust)
GMM_3 <- Mclust(X,G=3)
clust.ind <- GMM_3$classification
summary(GMM_3,parameters=TRUE) 
# chooses model with VVV varying shape, valume and orientatin
# df in model = equal to number of params in model
# covariance matrixes are symetric
# GMM_3$classification is telling is to which cluster each observation is assigned
```

```{r,fig.asp=1}
plot(GMM_3, what="classification",asp=1)
# points are mean of cluster
# asp is used for apect ratio between axes
```
```{r,fig.asp=1}
plot(GMM_3, what="density",asp=1)
points(X)
```

```{r,fig.asp=1}
plot(X,col=clust.ind,asp=1)
```

3. For each one of the $k$ clusters obtained above, do the following tasks *(A unique plot should be done, at which the $k$ densities are represented simultaneously)*:
- Consider the bivariate data set of the points in this cluster.
- Estimate non-parametrically the joint density of `lstat` and `rm`, conditional to this cluster *(Use the optimal bandwith found in the first point)*.
- Represent the estimated bivariate density using the level curve that covers the 75% of the points in this cluster.
 

```{r densities,fig.asp=1,warning=FALSE, message=FALSE}
library(sm)
plot(X,col=clust.ind,asp=1)
for (j in 1:k){
  cl.j <- (clust.ind==j)
  sm.density(X[cl.j,],h=a.opt*c(1,1), 
             display="slice",props=c(75),
             col=j, cex=4, add=TRUE)
}
```

4. Choose the best number of clusters $k\in\{2,\ldots,6\}$ according to BIC.

```{r BIC}
GMM_BIC <- Mclust(X,G=2:6)
summary(GMM_BIC,parameters=TRUE)
```

```{r,fig.asp=1}
plot(GMM_BIC, what="BIC",asp=1)
# see what model optains the best (highest) value for the bic
# as the functoni Mclust is trying to maximze the BIC
# model VVV with 3 clusters gives as the highest value
```

```{r,fig.asp=1}
plot(GMM_BIC, what="classification",asp=1)
```

```{r,fig.asp=1}
plot(GMM_BIC, what="density",asp=1)
points(X)
```

